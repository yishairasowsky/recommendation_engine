{"cells":[{"metadata":{"_cell_guid":"c16978a7-bb8f-787a-c584-d7d119acb674"},"cell_type":"markdown","source":"# Product Recommendation Engine"},{"metadata":{"_cell_guid":"ff7f9f14-a547-00be-24b4-c77140f3afc7"},"cell_type":"markdown","source":"## Step 1 - Train the engine.\n"},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"_cell_guid":"07c87a84-a1ab-aac2-b6ae-db0dbf8e49c1","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Examine Data"},{"metadata":{"_cell_guid":"07c87a84-a1ab-aac2-b6ae-db0dbf8e49c1","trusted":true},"cell_type":"code","source":"ds = pd.read_csv(\"../input/sample-data.csv\")\nds.tail()","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"      id                                        description\n495  496  Cap 2 bottoms - Cut loose from the maddening c...\n496  497  Cap 2 crew - This crew takes the edge off fick...\n497  498  All-time shell - No need to use that morning T...\n498  499  All-wear cargo shorts - All-Wear Cargo Shorts ...\n499  500  All-wear shorts - Time to simplify? Our All-We...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>495</th>\n      <td>496</td>\n      <td>Cap 2 bottoms - Cut loose from the maddening c...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>497</td>\n      <td>Cap 2 crew - This crew takes the edge off fick...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>498</td>\n      <td>All-time shell - No need to use that morning T...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>499</td>\n      <td>All-wear cargo shorts - All-Wear Cargo Shorts ...</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>500</td>\n      <td>All-wear shorts - Time to simplify? Our All-We...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## TF-IDF Matrix"},{"metadata":{"_cell_guid":"07c87a84-a1ab-aac2-b6ae-db0dbf8e49c1","trusted":true},"cell_type":"code","source":"#Create a TF-IDF matrix of unigrams, bigrams, and trigrams for each product. \ntf = TfidfVectorizer(\n    analyzer='word', \n    ngram_range=(1, 3), \n    min_df=0, \n    stop_words='english'#The 'stop_words' param tells the TF-IDF module to ignore common english words like 'the', etc.\n)\n\ntfidf_matrix = tf.fit_transform(\n    ds['description']\n)","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"07c87a84-a1ab-aac2-b6ae-db0dbf8e49c1","trusted":true},"cell_type":"code","source":"# Then we compute similarity between all products \n# using SciKit Leanr's linear_kernel (which in this case \n# is equivalent to cosine similarity).\ncosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"07c87a84-a1ab-aac2-b6ae-db0dbf8e49c1","trusted":true},"cell_type":"code","source":"results = {}\n# Iterate through each item's similar items and store the 100 most-similar. \n# Stops at 100 because well...how many similar products do you really need to show?\nfor idx, row in ds.iterrows():\n    similar_indices = cosine_similarities[idx].argsort()[:-100:-1]\n    similar_items = [(cosine_similarities[idx][i], ds['id'][i]) for i in similar_indices]\n    # Similarities and their scores are stored in a dict as a list of Tuples, \n    # indexed to their item id.\n    # First item is the item itself, so remove it.\n    # Each dictionary entry is like: [(1,2), (3,4)], with each tuple being (score, item_id)\n    results[row['id']] = similar_items[1:]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"28f7812a-5b05-db75-4c27-98517c18ba1b"},"cell_type":"markdown","source":"## Step 2: Predict!"},{"metadata":{"_cell_guid":"a8905407-854c-eb81-d952-5b4d26ccd6c2","trusted":true},"cell_type":"code","source":"# hacky little function to get a friendly item name from the description field, given an item ID\ndef item(id):\n    return ds.loc[ds['id'] == id]['description'].tolist()[0].split(' - ')[0]\n\n# Just reads the results out of the dictionary. No real logic here.\ndef recommend(item_id, num):\n    print(\"Recommending \" + str(num) + \" products similar to \" + item(item_id) + \"...\")\n    print(\"-------\")\n    recs = results[item_id][:num]\n    for rec in recs:\n        print(\"Recommended: \" + item(rec[1]) + \" (score:\" + str(rec[0]) + \")\")\n\n# Just plug in any item id here (1-500), and the number of recommendations you want (1-99)\n# You can get a list of valid item IDs by evaluating the variable 'ds', or a few are listed below\n\nrecommend(item_id=255, num=3)","execution_count":18,"outputs":[{"output_type":"stream","text":"Recommending 3 products similar to Solid sunamee btm...\n-------\nRecommended: Print sunamee btm (score:0.9691357121396879)\nRecommended: Print bayonne btm (score:0.4943344107191859)\nRecommended: Solid adour btm (score:0.48881326636069045)\n","name":"stdout"}]}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}